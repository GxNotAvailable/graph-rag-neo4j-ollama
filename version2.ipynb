{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "检索结果可视化，在图谱中特殊标注\n",
    "分为四个等级，完全正确，部分正确，部分相关，完全不相关。针对graph rag和直接使用llm进行对比"
   ],
   "id": "a5c0ff646f9d1f2"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-28T07:15:15.730171Z",
     "start_time": "2025-04-28T07:15:05.601767Z"
    }
   },
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "\n",
    "from sentence_transformers import CrossEncoder\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "llm = OllamaFunctions(model=\"qwen2.5\", temperature=0, format=\"json\") #可以替换成llama3\n",
    "\n",
    "reranker = 'BAAI/bge-reranker-base'\n",
    "# reranker = 'cross-encoder/ms-marco-MiniLM-L-6-v2'\n",
    "\n",
    "# # jina-embeddings-v3\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# class HuggingfaceEmbedding:\n",
    "#     def __init__(self, model):\n",
    "#         self.model = SentenceTransformer(model, trust_remote_code=True)\n",
    "#         self.model = self.model.to(device)\n",
    "# \n",
    "#     def __call__(self, texts):\n",
    "#         return self.model.encode(texts, device=device)\n",
    "# \n",
    "# embeddings = HuggingfaceEmbedding(\"jinaai/jina-embeddings-v3\")\n",
    "\n",
    "# bge-large\n",
    "class NewOllamaEmbeddings:\n",
    "    def __init__(self, model):\n",
    "        self.model = OllamaEmbeddings(model=model)\n",
    "\n",
    "    def __call__(self, texts):\n",
    "        return self.model.embed_query(texts)\n",
    "\n",
    "Embedding_Model = \"bge-large\"\n",
    "embeddings = NewOllamaEmbeddings(\n",
    "            model=Embedding_Model,\n",
    "        )"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 2\n",
      "Python-dotenv could not parse statement starting at line 3\n",
      "Python-dotenv could not parse statement starting at line 4\n",
      "Python-dotenv could not parse statement starting at line 5\n",
      "C:\\Users\\86159\\AppData\\Local\\Temp\\ipykernel_19232\\134212079.py:20: LangChainDeprecationWarning: The class `OllamaFunctions` was deprecated in LangChain 0.0.64 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = OllamaFunctions(model=\"qwen2.5\", temperature=0, format=\"json\") #可以替换成llama3\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T07:15:15.762112Z",
     "start_time": "2025-04-28T07:15:15.744113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # load data\n",
    "# def load_excel_data(file):\n",
    "#     df = pd.read_excel(file)\n",
    "#     \n",
    "#     nodes = {\n",
    "#         \"现象\":df[\"现象\"].dropna().unique(),\n",
    "#         \"原因\":df[\"原因\"].dropna().unique(),\n",
    "#         \"部件\":df[\"部件\"].dropna().unique(),\n",
    "#         \"处理方法\":df[\"处理方法\"].dropna().unique(),\n",
    "#     }\n",
    "#     \n",
    "#     relationships = []\n",
    "#     for _, row in df.iterrows():\n",
    "#         relationships.append({\n",
    "#             \"现象\": row[\"现象\"],\n",
    "#             \"原因\": row[\"原因\"],\n",
    "#             \"部件\": row[\"部件\"],\n",
    "#             \"处理方法\": row[\"处理方法\"],\n",
    "#         })\n",
    "#         \n",
    "#     return nodes, relationships\n",
    "# \n",
    "# file_path = \"故障四元组.xlsx\"\n",
    "# nodes, relationships = load_excel_data(file_path)"
   ],
   "id": "429a388d6c9b70e1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T07:15:18.334439Z",
     "start_time": "2025-04-28T07:15:15.773422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# 图数据库\n",
    "# create graph database\n",
    "class Neo4jGraphManager:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "        self.embeddings = embeddings\n",
    "        \n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "        \n",
    "    def clear_database(self):\n",
    "        with self.driver.session() as session:\n",
    "            try:\n",
    "                session.run(\"DROP INDEX vector_index IF EXISTS\")\n",
    "                session.run(\"DROP INDEX text_index IF EXISTS\")\n",
    "            except Exception as e:\n",
    "                print(f\"warning when dropping index : {str(e)}\")\n",
    "            \n",
    "            session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "            \n",
    "    def insert_node_with_embedding(self, label, properties):\n",
    "        with self.driver.session() as session:\n",
    "            embedding = self.embeddings(properties[\"text\"])\n",
    "            \n",
    "            query = f\"\"\"\n",
    "            CREATE (n:{label}{{\n",
    "                name: $name,\n",
    "                text: $text,\n",
    "                embedding: $embedding,\n",
    "                uuid: $uuid\n",
    "            }})\n",
    "            RETURN n.uuid AS node_id\n",
    "            \"\"\"\n",
    "            \n",
    "            result = session.run(query,{\n",
    "                \"name\": properties[\"name\"],\n",
    "                \"text\": properties[\"text\"],\n",
    "                \"embedding\": embedding,\n",
    "                \"uuid\": str(uuid.uuid4())\n",
    "            })\n",
    "            \n",
    "            return result.single()[\"node_id\"]\n",
    "        \n",
    "    def insert_relationship(self, start_label, start_name, end_label, end_name, relationship_type):\n",
    "        with self.driver.session() as session:\n",
    "            \n",
    "            check_start_query = f\"\"\"\n",
    "            MATCH (a:{start_label} {{name: $start_name}})\n",
    "            RETURN count(a) > 0 AS node_exists\n",
    "            \"\"\"\n",
    "            \n",
    "            start_node_exists = session.run(check_start_query, {\"start_name\": start_name}).single()[\"node_exists\"]\n",
    "            \n",
    "            if not start_node_exists:\n",
    "                raise ValueError(f\"start node {start_label} (name={start_name}) does not exist\")\n",
    "            \n",
    "            check_end_query = f\"\"\"\n",
    "            MATCH (a:{end_label} {{name: $end_name}})\n",
    "            RETURN count(a) > 0 AS node_exists\n",
    "            \"\"\"\n",
    "            \n",
    "            end_node_exists = session.run(check_end_query, {\"end_name\": end_name}).single()[\"node_exists\"]\n",
    "            \n",
    "            if not end_node_exists:\n",
    "                raise ValueError(f\"end node {end_label} (name={end_name}) does not exist\")\n",
    "            \n",
    "            query = f\"\"\"\n",
    "            MATCH (a:{start_label} {{name: $start_name}})\n",
    "            MATCH (b:{end_label} {{name: $end_name}})\n",
    "            MERGE (a)-[r:{relationship_type}]->(b)\n",
    "            RETURN type(r) AS relationship_type\n",
    "            \"\"\"\n",
    "            result = session.run(query, {\"start_name\": start_name, \"end_name\": end_name})\n",
    "            \n",
    "            return result.single()[\"relationship_type\"]\n",
    "        \n",
    "    def create_indexes(self):\n",
    "        # create indexes to accelerate the query for \"现象\"\n",
    "        with self.driver.session() as session:\n",
    "            try:\n",
    "                session.run(\"\"\"\n",
    "                CREATE VECTOR INDEX vector_index IF NOT EXISTS\n",
    "                FOR (n:现象)\n",
    "                ON (n.embedding)\n",
    "                OPTIONS {\n",
    "                indexConfig: {\n",
    "                    `vector.dimensions`: 1024,\n",
    "                    `vector.similarity_function`: 'cosine'\n",
    "                }\n",
    "            }\n",
    "                \"\"\")\n",
    "                \n",
    "                session.run(\"CALL db.awaitIndexes(300)\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Creating vector indexes failed : {str(e)}\")\n",
    "            \n",
    "            try:\n",
    "                session.run(\"\"\"\n",
    "                CREATE TEXT INDEX text_index IF NOT EXISTS\n",
    "                FOR (n:现象)\n",
    "                ON (n.text)\n",
    "                \"\"\")\n",
    "                \n",
    "                session.run(\"CALL db.awaitIndexes(300)\")\n",
    "            except Exception as e:\n",
    "                print(f\"Creating text indexes failed : {str(e)}\")\n",
    "                \n",
    "    def verify_indexes(self):\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(\"\"\"\n",
    "            SHOW INDEXES\n",
    "            YIELD name, labelsOrTypes, properties, state\n",
    "            WHERE name IN ['vector_index', 'text_index']\n",
    "            RETURN name, state\n",
    "            \"\"\")\n",
    "            \n",
    "            indexes = {record[\"name\"]: record[\"state\"] for record in result}\n",
    "            \n",
    "            missing_indexes = []\n",
    "            if 'vector_index' not in indexes:\n",
    "                missing_indexes.append(\"Vector index\")\n",
    "            if 'text_index' not in indexes:\n",
    "                missing_indexes.append(\"Text index\")\n",
    "\n",
    "            if missing_indexes:\n",
    "                print(f\"{', '.join(missing_indexes)} missing, creating...\")\n",
    "                self.create_indexes()\n",
    "                \n",
    "            elif indexes['text_index'] != 'ONLINE':\n",
    "                print(f\"Vector index state: {indexes['vector_index']}, waiting...\")\n",
    "                session.run(\"CALL db.awaitIndexes(300)\")\n",
    "\n",
    "\n",
    "            elif indexes['vector_index'] != 'ONLINE':\n",
    "                print(f\"Vector index state: {indexes['vector_index']}, waiting...\")\n",
    "                session.run(\"CALL db.awaitIndexes(300)\")\n",
    "                \n",
    "    def retrieve_with_priority(self, query:str, k=3):\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            print(f\"[DEBUG] Query: {query}\")\n",
    "            embedding = self.embeddings(query)\n",
    "            print(f\"[DEBUG] Generated embedding for query: {embedding[:5]}... (truncated for brevity)\")\n",
    "            \n",
    "            # contains 检索\n",
    "            graph_query = \"\"\"\n",
    "            MATCH (n)\n",
    "            WHERE n.text CONTAINS $query_text\n",
    "            RETURN n.text AS text, n.name AS name, n.uuid AS uuid\n",
    "            LIMIT $k\n",
    "            \"\"\"\n",
    "            \n",
    "            graph_results = session.run(graph_query, {\"query_text\": query, \"k\": k})\n",
    "            graph_matches = [\n",
    "                {\"uuid\": record[\"uuid\"], \"text\": record[\"text\"]}\n",
    "                for record in graph_results\n",
    "            ]\n",
    "            print(f\"[DEBUG] Graph database matches found: {len(graph_matches)}\")\n",
    "            \n",
    "            # 向量检索,余弦相似度\n",
    "            try:\n",
    "                vector_results = session.run(\"\"\"\n",
    "                MATCH (n:现象)\n",
    "                WHERE n.embedding IS NOT NULL\n",
    "                RETURN n.text AS text, n.uuid AS uuid,\n",
    "                    vector.similarity.cosine(n.embedding, $embedding) AS score\n",
    "                ORDER BY score DESC\n",
    "                LIMIT $k\n",
    "                \"\"\",{\n",
    "                    \"embedding\": embedding,\n",
    "                    \"k\": k\n",
    "                })\n",
    "                \n",
    "                vector_matches = []\n",
    "                for record in vector_results:\n",
    "                    vector_matches.append({\n",
    "                        \"uuid\" : record[\"uuid\"],\n",
    "                        \"text\" : record[\"text\"],\n",
    "                        \"score\" : record[\"score\"]\n",
    "                    })\n",
    "                print(f\"[DEBUG] Vector search matches found: {vector_matches}\")\n",
    "                print(f\"[DEBUG] Vector search matches found: {len(vector_matches)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"[DEBUG] Vector search failed : {str(e)}\")\n",
    "                vector_matches = []\n",
    "                \n",
    "            # Remove the 'score' field from vector_matches\n",
    "            for item in vector_matches:\n",
    "                item.pop('score', None)\n",
    "            \n",
    "            # Create a set of UUIDs from graph_matches\n",
    "            graph_uuids = {item['uuid'] for item in graph_matches}\n",
    "            \n",
    "            # Add items from graph_matches to combined_results only if their UUID is not in vector_matches\n",
    "            combined_results = graph_matches + [\n",
    "                item for item in vector_matches if item['uuid'] not in graph_uuids\n",
    "            ]\n",
    "            \n",
    "            print(f\"[DEBUG] Combined search results: {len(combined_results)}\")\n",
    "                    \n",
    "            return combined_results\n",
    "        \n",
    "\n",
    "\n",
    "def showGraph():\n",
    "    driver = GraphDatabase.driver(\n",
    "        uri = os.environ[\"NEO4J_URI\"],\n",
    "        auth = (os.environ[\"NEO4J_USERNAME\"],\n",
    "                os.environ[\"NEO4J_PASSWORD\"]))\n",
    "    session = driver.session()\n",
    "    widget = GraphWidget(graph=session.run(\"MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t\").graph())\n",
    "    widget.node_label_mapping = 'name'\n",
    "    return widget\n",
    "\n",
    "showGraph()\n",
    "                \n",
    "# # construct graph database        \n",
    "# graph_manager = Neo4jGraphManager(uri=os.environ[\"NEO4J_URI\"], user=os.environ[\"NEO4J_USERNAME\"], password=os.environ[\"NEO4J_PASSWORD\"])\n",
    "# graph_manager.show_graph()\n",
    "# \n",
    "# graph_manager.clear_database()\n",
    "# \n",
    "# for label, names in nodes.items():\n",
    "#     for name in names:\n",
    "#         graph_manager.insert_node_with_embedding(label=label, properties={\"name\": name, \"text\": name})\n",
    "# \n",
    "# for rel in relationships:\n",
    "#     graph_manager.insert_relationship(\"现象\", rel[\"现象\"], \"原因\", rel[\"原因\"],\"原因\")\n",
    "#     graph_manager.insert_relationship(\"现象\", rel[\"现象\"], \"部件\", rel[\"部件\"],\"涉及的部件\")\n",
    "#     graph_manager.insert_relationship(\"现象\", rel[\"现象\"], \"处理方法\", rel[\"处理方法\"],\"处理方法\")\n",
    "# \n",
    "# # create index\n",
    "# graph_manager.create_indexes()\n",
    "# graph_manager.verify_indexes()\n",
    "# \n",
    "# print(\"[DEBUG] Construction successfully finished\")\n",
    "# \n",
    "# graph_manager.close()\n",
    "# \n",
    "# # test retriever\n",
    "# graph_manager = Neo4jGraphManager(uri=os.environ[\"NEO4J_URI\"], user=os.environ[\"NEO4J_USERNAME\"], password=os.environ[\"NEO4J_PASSWORD\"])\n",
    "# print(graph_manager.retrieve_with_priority(\"天线不转动\"))\n",
    "# graph_manager.close()"
   ],
   "id": "505cb44843530bca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphWidget(layout=Layout(height='800px', width='100%'))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f8525a5fcbf4033b2e9e675529bda0b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-28T07:15:18.784494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RAGPipeline:\n",
    "    def __init__(self, graph_manager, llm=llm,embeddings=embeddings,reranker=reranker):\n",
    "        self.graph_manager = graph_manager\n",
    "        self.llm = llm\n",
    "        self.embeddings = embeddings\n",
    "        self.reranker = reranker\n",
    "        self.history = []\n",
    "    \n",
    "    # 处理询问\n",
    "    def refine_query(self, query):\n",
    "        prompt_template = \"\"\"请你从<语句>中提取<现象>，仅仅提取原话中描述故障现象的内容，不添加任何解释或改动。\n",
    "            示例：\n",
    "            <语句>：波导内积水如何处理\n",
    "            <现象>：波导内积水\n",
    "            <语句>：荧光屏不亮是怎么回事\n",
    "            <现象>：荧光屏不亮\n",
    "            <语句>：而且高压指示灯亮起\n",
    "            <现象>：高压指示灯亮起\n",
    "            \n",
    "            请从语句中提取现象：\n",
    "            <语句>：{query}\n",
    "            <现象>：\n",
    "            \"\"\"\n",
    "        prompt = prompt_template.format(query=query)\n",
    "        try:\n",
    "            # 调用LLM\n",
    "            response = self.llm.invoke(prompt)\n",
    "            # 假设LLM返回的JSON包含\"故障现象\"字段\n",
    "            refined_query = response.content  # 如果提取失败，回退到原始查询\n",
    "            print(f\"[DEBUG] Refined Query (via LLM): {refined_query}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[DEBUG] LLM refinement failed: {str(e)}, falling back to original query\")\n",
    "            refined_query = query  # 如果LLM调用失败，回退到原始查询\n",
    "        return refined_query\n",
    "            \n",
    "    \n",
    "    # 计算BM25分数\n",
    "    def Cal_BM25(self, query, k=5):\n",
    "        \"\"\"\n",
    "        使用 jieba 分词计算 BM25 得分\n",
    "        :param query: 查询文本 (str)\n",
    "        :param graph_manager: 图数据库接口\n",
    "        :param k: 返回前 k 个结果\n",
    "        :return: BM25 匹配结果 (list of dict)\n",
    "        \"\"\"\n",
    "        bm25_matches = []\n",
    "        with self.graph_manager.driver.session() as session:\n",
    "            all_docs = session.run(\"MATCH (n:现象) RETURN n.text AS text\")  \n",
    "            # 1. 处理文档集合\n",
    "            documents = [record[\"text\"] for record in all_docs]\n",
    "            # print(f\"[DEBUG] Documents: {documents}\")\n",
    "            \n",
    "            # 使用 jieba 分词处理文档\n",
    "            tokenized_corpus = [list(jieba.cut(doc)) for doc in documents]  # 对每个文档分词\n",
    "            # print(f\"[DEBUG] Tokenized Corpus: {tokenized_corpus}\")\n",
    "            \n",
    "            # 初始化 BM25 模型\n",
    "            bm25 = BM25Okapi(tokenized_corpus)\n",
    "        \n",
    "        # 2. BM25 检索\n",
    "        try:\n",
    "            # 使用 jieba 分词处理查询\n",
    "            tokenized_query = list(jieba.cut(query))\n",
    "            # print(f\"[DEBUG] Tokenized Query: {tokenized_query}\")\n",
    "            \n",
    "            # 计算 BM25 得分\n",
    "            bm25_scores = bm25.get_scores(tokenized_query)\n",
    "            bm25_top_k = np.argsort(bm25_scores)[::-1][:k]  # 取前 k 个得分最高的文档\n",
    "            \n",
    "            # 存储匹配结果\n",
    "            for idx in bm25_top_k:\n",
    "                bm25_matches.append({\n",
    "                    'text': documents[idx],\n",
    "                    'bm25_score': bm25_scores[idx]\n",
    "                })\n",
    "                print(f\"[DEBUG] BM25 search matches found: {documents[idx]} (score: {bm25_scores[idx]:.3f})\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"[DEBUG] BM25 search failed: {str(e)}\")\n",
    "            bm25_matches = []\n",
    "        \n",
    "        return bm25_matches\n",
    "\n",
    "    # 计算向量相似度\n",
    "    def Cal_Similarity(self, query, k=5):\n",
    "        vector_matches = []\n",
    "        try:\n",
    "            query_embedding = self.embeddings(query)\n",
    "            print(f\"[DEBUG] Query embedding: {query_embedding[:5]}...(truncated for brevity)\")\n",
    "            print(f\"[DEBUG] Vector length: {len(query_embedding)}\")\n",
    "            \n",
    "            with self.graph_manager.driver.session() as session:\n",
    "                index_check = session.run(\"\"\"\n",
    "                SHOW INDEXES\n",
    "                YIELD name, labelsOrTypes, properties\n",
    "                WHERE name = 'vector_index'\n",
    "                RETURN count(*) as count\n",
    "                \"\"\")\n",
    "                \n",
    "                if index_check.single()['count'] == 0:\n",
    "                    print(f\"[DEBUG] Vector index not found, creating index...\")\n",
    "                    self.graph_manager.create_indexes()\n",
    "                \n",
    "                vector_results = session.run(\"\"\"\n",
    "                CALL db.index.vector.queryNodes('vector_index', $k, $embedding)\n",
    "                YIELD node, score\n",
    "                RETURN node.text AS text, score AS score\n",
    "                ORDER BY score DESC\n",
    "                \"\"\", {\"k\":k, \"embedding\":query_embedding})\n",
    "                \n",
    "                for record in vector_results:\n",
    "                    vector_matches.append({\n",
    "                        'text': record['text'],\n",
    "                        'vector_score': record['score']\n",
    "                    })\n",
    "                    print(f\"[DEBUG] Vector search matches found: {record['text']}(vector_score: {record['score']:.3f})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"[DEBUG] Vector search failed : {str(e)}\") \n",
    "            vector_matches = []\n",
    "        \n",
    "        print(f\"[DEBUG] Vector result count: {len(vector_matches)}\")\n",
    "        return vector_matches\n",
    "\n",
    "    # BM25+向量混合检索\n",
    "    def hybrid_retriever(self, query, bm25_weight=0.3, vector_weight=0.7, k=5):\n",
    "        bm25_matches = self.Cal_BM25(query,  k=k)\n",
    "        vector_matches = self.Cal_Similarity(query, k=k)\n",
    "        combined_matches = {}\n",
    "        for match in vector_matches:\n",
    "            combined_matches[match['text']] = {'vector_score': match['vector_score'], 'bm25_score': 0.0}\n",
    "        for match in bm25_matches:\n",
    "            if match['text'] in combined_matches:\n",
    "                combined_matches[match['text']]['bm25_score'] = match['bm25_score']\n",
    "            else:\n",
    "                combined_matches[match['text']] = {'vector_score': 0.0, 'bm25_score': match['bm25_score']}\n",
    "    \n",
    "        # 计算融合得分\n",
    "        for text, scores in combined_matches.items():\n",
    "            hybrid_score = bm25_weight * scores['bm25_score'] + vector_weight * scores['vector_score']\n",
    "            combined_matches[text]['hybrid_score'] = hybrid_score\n",
    "    \n",
    "        # 转换为列表并排序\n",
    "        rerank_input = [{'text': text, 'hybrid_score': scores['hybrid_score']} \n",
    "                        for text, scores in combined_matches.items()]\n",
    "        reranked_matches = sorted(rerank_input, key=lambda x: x['hybrid_score'], reverse=True)\n",
    "        return reranked_matches\n",
    "\n",
    "    # 使用cross_encoder重排序\n",
    "    def rerank_with_cross_encoder(self, query: str, matches: list, top_k: int = 5, alpha: int = 0.99, beta : int = 0.01) -> list:\n",
    "        \"\"\"\n",
    "        使用中文优化的 Cross-Encoder 对混合检索结果进行重排序\n",
    "        :param query: 查询文本 (中文)\n",
    "        :param matches: 混合检索结果 (list of dict, 包含 'text' 和 'hybrid_score')\n",
    "        :param top_k: 返回前 k 个结果\n",
    "        :param alpha: cross_encoder占比\n",
    "        :param beta: hybrid_score占比\n",
    "        :return: 重排序后的结果\n",
    "        \"\"\"\n",
    "        # 初始化中文 Cross-Encoder 模型\n",
    "        model = CrossEncoder(self.reranker)\n",
    "        \n",
    "        # 准备输入：查询和候选文档对\n",
    "        pairs = [[query, match['text']] for match in matches]\n",
    "        # print(f\"[DEBUG] Cross-Encoder input pairs: {pairs}\")\n",
    "        \n",
    "        # 计算相关性得分\n",
    "        scores = model.predict(pairs)\n",
    "        # print(f\"[DEBUG] Cross-Encoder scores: {scores}\")\n",
    "        \n",
    "        # 将得分添加到 matches 中\n",
    "        for match, score in zip(matches, scores):\n",
    "            match['cross_encoder_score'] = float(score)  # 转换为 float 以便排序\n",
    "        \n",
    "        # 按 Cross-Encoder 得分排序\n",
    "        reranked_matches = sorted(matches, key=lambda x: x['cross_encoder_score']*alpha + x['hybrid_score']*beta, reverse=True)\n",
    "        \n",
    "        print(reranked_matches[:top_k])\n",
    "        # 返回前 top_k 个结果\n",
    "        return reranked_matches[:top_k]\n",
    "    \n",
    "    # 将检索的结果处理为字符串上下文\n",
    "    def format_results(self, results, K):\n",
    "        response = []\n",
    "        if results:\n",
    "            graph_matches = [r for r in results if r['relation'] != 'vector_match']\n",
    "            if graph_matches:\n",
    "                response.append(\"检索结果:\")\n",
    "                for rel in graph_matches:\n",
    "                    # response.append(\n",
    "                    #     f\"• {rel['phenomenon']}-{rel['relation']}->{rel['target']}(相关度: {rel['score']:.3f})\")\n",
    "                    response.append(\n",
    "                        f\"• {rel['phenomenon']}-{rel['relation']}->{rel['target']}\")\n",
    "                    \n",
    "                response.append(\"\")\n",
    "            \n",
    "            vector_only = [r for r in results if r['relation'] == 'vector_only']\n",
    "            \n",
    "            if vector_only:\n",
    "                response.append(\"向量检索结果:\")\n",
    "                for rel in vector_only:\n",
    "                    response.append(f\"• {rel['phenomenon']}——缺少相关条目\")\n",
    "        \n",
    "        return \"\\n\".join(response[:min(K+1, len(response))])\n",
    "    \n",
    "    # 完整的检索功能\n",
    "    def retriever(self, query, k=4, K=15):\n",
    "        final_result = []\n",
    "        \n",
    "        matches = self.hybrid_retriever(query)\n",
    "        reranked_matches = self.rerank_with_cross_encoder(query, matches, top_k=k)\n",
    "        \n",
    "        with self.graph_manager.driver.session() as session:\n",
    "            for match in reranked_matches:\n",
    "                text = match['text']\n",
    "                score = match['cross_encoder_score']\n",
    "                \n",
    "                graph_results = session.run(\"\"\"\n",
    "                MATCH (p: 现象)-[r]->(n)\n",
    "                WHERE p.text contains $text\n",
    "                RETURN p.text as phenomenon, type(r) as relation, n.text as target\n",
    "                \"\"\", text=text)\n",
    "                \n",
    "                relationships = []\n",
    "                for record in graph_results:\n",
    "                    relationships.append({\n",
    "                        'phenomenon': record['phenomenon'],\n",
    "                        'relation': record['relation'],\n",
    "                        'target': record['target'],\n",
    "                        'score': score\n",
    "                    })\n",
    "                \n",
    "                if relationships:\n",
    "                    final_result.extend(relationships)\n",
    "                else:\n",
    "                    final_result.append({\n",
    "                        'phenomenon': text,\n",
    "                        'relation': 'vector_match',\n",
    "                        'target': 'N/A',\n",
    "                        'text': text,\n",
    "                        'score': score\n",
    "                    })\n",
    "        context = self.format_results(final_result, K)\n",
    "        print(\"[DEGUG] context:\" + context)\n",
    "        return context\n",
    "    \n",
    "    def generate_answer(self, query, context):\n",
    "        history_str = \"\\n\".join([f\"Q: {q}\\nA: {a}\" for q, p, a in self.history]) if self.history else \"无\"\n",
    "        # 构造提示词\n",
    "        prompt = f\"\"\"\n",
    "        基于以下对话历史和检索到的相关信息回答问题并给出维修建议：\n",
    "\n",
    "        对话历史：\n",
    "        {history_str}\n",
    "\n",
    "        当前检索到的信息：\n",
    "        {context}\n",
    "\n",
    "        问题：\n",
    "        {query}\n",
    "\n",
    "        请提供清晰简洁的答案。注意：\n",
    "        1. 如果检索到了信息，请整合信息中的原话,按照类别分条回答\n",
    "        2. 如果提供的信息和对话历史不足以回答问题，请直接说明\"根据现有信息无法完整回答该问题\"\n",
    "        3. 如果问题与对话历史相关，请结合历史信息回答\n",
    "\n",
    "        答案：\n",
    "        \"\"\"\n",
    "        \n",
    "        # 调用 LLM\n",
    "        response = llm.invoke(prompt)\n",
    "        answer = response.content.strip()\n",
    "        return answer\n",
    "        \n",
    "    def ask(self, query):\n",
    "        ## 多轮问询结合\n",
    "        # 拼接query\n",
    "        all_query = \",\".join(q for q,p,a in self.history) if self.history else \"\"\n",
    "        all_query += query\n",
    "        phenomenon = self.refine_query(query)\n",
    "        phenomenons = \",\".join(p for q,p,a in self.history) if self.history else \"\" \n",
    "        \n",
    "        context = self.retriever(phenomenons + phenomenon)\n",
    "        answer = self.generate_answer(all_query, context)\n",
    "        \n",
    "        self.history.append((query,phenomenon, answer))\n",
    "        if len(self.history) > 3:  # 限制历史长度，避免上下文过长\n",
    "            self.history.pop(0)\n",
    "        \n",
    "        return answer\n",
    "    \n",
    "    def check_memory(self):\n",
    "        print(self.history)\n",
    "    \n",
    "\n",
    "graph_manager = Neo4jGraphManager(uri=os.environ[\"NEO4J_URI\"], user=os.environ[\"NEO4J_USERNAME\"],password=os.environ[\"NEO4J_PASSWORD\"])\n",
    "\n",
    "rag = RAGPipeline(graph_manager)\n",
    "# query1 = \"荧光屏上没有回波是怎么回事\"\n",
    "query1 = \"What causes Antenna not rotating?\"\n",
    "answer = rag.ask(query1)\n",
    "print(answer)\n",
    "# query2 = \"且用氛灯放在天线当中检查时氛灯辉亮\"\n",
    "# answer = rag.ask(query2)\n",
    "# print(answer)\n",
    "# query3 = \"且没有混频晶体电流或者混频晶体电流很小\"\n",
    "# answer = rag.ask(query3)\n"
   ],
   "id": "6f03769ab4c7d380",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\86159\\AppData\\Local\\Temp\\jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] LLM refinement failed: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/chat (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000020D512339A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。')), falling back to original query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.614 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] BM25 search matches found: 磁控管电流不稳定 ，时时抖动 (score: 7.839)\n",
      "[DEBUG] BM25 search matches found: 磁控管电流不稳定 ，加高压后打火，引起磁控管电流抖动 (score: 5.747)\n",
      "[DEBUG] BM25 search matches found: 天线不转动，荧光屏上扫描线旋转, 有很多个同心的辉亮圆环 (score: 5.340)\n",
      "[DEBUG] BM25 search matches found: 磁控管电流不稳定 ，时时抖动，在阻尼二极管打火时，荧光屏中心出现辉亮 (score: 4.987)\n",
      "[DEBUG] BM25 search matches found: 磁控管电流太小 (score: 0.000)\n",
      "[DEBUG] Vector search failed : Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download\n",
      "[DEBUG] Vector result count: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTimeoutError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py:85\u001B[0m, in \u001B[0;36mcreate_connection\u001B[1;34m(address, timeout, source_address, socket_options)\u001B[0m\n\u001B[0;32m     84\u001B[0m     sock\u001B[38;5;241m.\u001B[39mbind(source_address)\n\u001B[1;32m---> 85\u001B[0m \u001B[43msock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43msa\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sock\n",
      "\u001B[1;31mTimeoutError\u001B[0m: timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 301\u001B[0m\n\u001B[0;32m    299\u001B[0m \u001B[38;5;66;03m# query1 = \"荧光屏上没有回波是怎么回事\"\u001B[39;00m\n\u001B[0;32m    300\u001B[0m query1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhat causes Antenna not rotating?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 301\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[43mrag\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mask\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    302\u001B[0m \u001B[38;5;28mprint\u001B[39m(answer)\n",
      "Cell \u001B[1;32mIn[4], line 283\u001B[0m, in \u001B[0;36mRAGPipeline.ask\u001B[1;34m(self, query)\u001B[0m\n\u001B[0;32m    280\u001B[0m phenomenon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrefine_query(query)\n\u001B[0;32m    281\u001B[0m phenomenons \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(p \u001B[38;5;28;01mfor\u001B[39;00m q,p,a \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhistory) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhistory \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m \n\u001B[1;32m--> 283\u001B[0m context \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretriever\u001B[49m\u001B[43m(\u001B[49m\u001B[43mphenomenons\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mphenomenon\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    284\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate_answer(all_query, context)\n\u001B[0;32m    286\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhistory\u001B[38;5;241m.\u001B[39mappend((query,phenomenon, answer))\n",
      "Cell \u001B[1;32mIn[4], line 211\u001B[0m, in \u001B[0;36mRAGPipeline.retriever\u001B[1;34m(self, query, k, K)\u001B[0m\n\u001B[0;32m    208\u001B[0m final_result \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    210\u001B[0m matches \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhybrid_retriever(query)\n\u001B[1;32m--> 211\u001B[0m reranked_matches \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrerank_with_cross_encoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmatches\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_k\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgraph_manager\u001B[38;5;241m.\u001B[39mdriver\u001B[38;5;241m.\u001B[39msession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m match \u001B[38;5;129;01min\u001B[39;00m reranked_matches:\n",
      "Cell \u001B[1;32mIn[4], line 161\u001B[0m, in \u001B[0;36mRAGPipeline.rerank_with_cross_encoder\u001B[1;34m(self, query, matches, top_k, alpha, beta)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    152\u001B[0m \u001B[38;5;124;03m使用中文优化的 Cross-Encoder 对混合检索结果进行重排序\u001B[39;00m\n\u001B[0;32m    153\u001B[0m \u001B[38;5;124;03m:param query: 查询文本 (中文)\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    158\u001B[0m \u001B[38;5;124;03m:return: 重排序后的结果\u001B[39;00m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;66;03m# 初始化中文 Cross-Encoder 模型\u001B[39;00m\n\u001B[1;32m--> 161\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mCrossEncoder\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreranker\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    163\u001B[0m \u001B[38;5;66;03m# 准备输入：查询和候选文档对\u001B[39;00m\n\u001B[0;32m    164\u001B[0m pairs \u001B[38;5;241m=\u001B[39m [[query, match[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m]] \u001B[38;5;28;01mfor\u001B[39;00m match \u001B[38;5;129;01min\u001B[39;00m matches]\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:82\u001B[0m, in \u001B[0;36mCrossEncoder.__init__\u001B[1;34m(self, model_name, num_labels, max_length, device, automodel_args, tokenizer_args, config_args, cache_dir, trust_remote_code, revision, local_files_only, default_activation_function, classifier_dropout)\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config_args \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     81\u001B[0m     config_args \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m---> 82\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig \u001B[38;5;241m=\u001B[39m AutoConfig\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[0;32m     83\u001B[0m     model_name,\n\u001B[0;32m     84\u001B[0m     trust_remote_code\u001B[38;5;241m=\u001B[39mtrust_remote_code,\n\u001B[0;32m     85\u001B[0m     revision\u001B[38;5;241m=\u001B[39mrevision,\n\u001B[0;32m     86\u001B[0m     local_files_only\u001B[38;5;241m=\u001B[39mlocal_files_only,\n\u001B[0;32m     87\u001B[0m     cache_dir\u001B[38;5;241m=\u001B[39mcache_dir,\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig_args,\n\u001B[0;32m     89\u001B[0m )\n\u001B[0;32m     90\u001B[0m classifier_trained \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39marchitectures \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1054\u001B[0m, in \u001B[0;36mAutoConfig.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[0;32m   1051\u001B[0m trust_remote_code \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrust_remote_code\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m   1052\u001B[0m code_revision \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode_revision\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m-> 1054\u001B[0m config_dict, unused_kwargs \u001B[38;5;241m=\u001B[39m PretrainedConfig\u001B[38;5;241m.\u001B[39mget_config_dict(pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1055\u001B[0m has_remote_code \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto_map\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAutoConfig\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto_map\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1056\u001B[0m has_local_code \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_type\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict \u001B[38;5;129;01mand\u001B[39;00m config_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_type\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;129;01min\u001B[39;00m CONFIG_MAPPING\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\configuration_utils.py:591\u001B[0m, in \u001B[0;36mPretrainedConfig.get_config_dict\u001B[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[0;32m    589\u001B[0m original_kwargs \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(kwargs)\n\u001B[0;32m    590\u001B[0m \u001B[38;5;66;03m# Get config dict associated with the base config file\u001B[39;00m\n\u001B[1;32m--> 591\u001B[0m config_dict, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_get_config_dict(pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    592\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    593\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {}, kwargs\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\configuration_utils.py:650\u001B[0m, in \u001B[0;36mPretrainedConfig._get_config_dict\u001B[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[0;32m    646\u001B[0m configuration_file \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_configuration_file\u001B[39m\u001B[38;5;124m\"\u001B[39m, CONFIG_NAME) \u001B[38;5;28;01mif\u001B[39;00m gguf_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m gguf_file\n\u001B[0;32m    648\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    649\u001B[0m     \u001B[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001B[39;00m\n\u001B[1;32m--> 650\u001B[0m     resolved_config_file \u001B[38;5;241m=\u001B[39m \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    651\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    652\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfiguration_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    653\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    654\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    655\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    656\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    657\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    658\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    659\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    660\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    661\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    662\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_commit_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    663\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    664\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m resolved_config_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    665\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, kwargs\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\utils\\hub.py:403\u001B[0m, in \u001B[0;36mcached_file\u001B[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[0;32m    400\u001B[0m user_agent \u001B[38;5;241m=\u001B[39m http_user_agent(user_agent)\n\u001B[0;32m    401\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    402\u001B[0m     \u001B[38;5;66;03m# Load from URL or cache if already cached\u001B[39;00m\n\u001B[1;32m--> 403\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    404\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    405\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    406\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    407\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    408\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    409\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    410\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    411\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    412\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    413\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    414\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    415\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    416\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    417\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m GatedRepoError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    418\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[0;32m    112\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[1;32m--> 114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\file_download.py:860\u001B[0m, in \u001B[0;36mhf_hub_download\u001B[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001B[0m\n\u001B[0;32m    840\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _hf_hub_download_to_local_dir(\n\u001B[0;32m    841\u001B[0m         \u001B[38;5;66;03m# Destination\u001B[39;00m\n\u001B[0;32m    842\u001B[0m         local_dir\u001B[38;5;241m=\u001B[39mlocal_dir,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    857\u001B[0m         local_files_only\u001B[38;5;241m=\u001B[39mlocal_files_only,\n\u001B[0;32m    858\u001B[0m     )\n\u001B[0;32m    859\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 860\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_hf_hub_download_to_cache_dir\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    861\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Destination\u001B[39;49;00m\n\u001B[0;32m    862\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    863\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# File info\u001B[39;49;00m\n\u001B[0;32m    864\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrepo_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    865\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    866\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    867\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    868\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# HTTP info\u001B[39;49;00m\n\u001B[0;32m    869\u001B[0m \u001B[43m        \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mendpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    870\u001B[0m \u001B[43m        \u001B[49m\u001B[43metag_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43metag_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    871\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhf_headers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    872\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    873\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    874\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Additional options\u001B[39;49;00m\n\u001B[0;32m    875\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    876\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\file_download.py:923\u001B[0m, in \u001B[0;36m_hf_hub_download_to_cache_dir\u001B[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001B[0m\n\u001B[0;32m    919\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m pointer_path\n\u001B[0;32m    921\u001B[0m \u001B[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001B[39;00m\n\u001B[0;32m    922\u001B[0m \u001B[38;5;66;03m# If we can't, a HEAD request error is returned.\u001B[39;00m\n\u001B[1;32m--> 923\u001B[0m (url_to_download, etag, commit_hash, expected_size, head_call_error) \u001B[38;5;241m=\u001B[39m \u001B[43m_get_metadata_or_catch_error\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    924\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrepo_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    925\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    926\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    927\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    928\u001B[0m \u001B[43m    \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mendpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    929\u001B[0m \u001B[43m    \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    930\u001B[0m \u001B[43m    \u001B[49m\u001B[43metag_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43metag_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    931\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    932\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    933\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    934\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    935\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrelative_filename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrelative_filename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    936\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    938\u001B[0m \u001B[38;5;66;03m# etag can be None for several reasons:\u001B[39;00m\n\u001B[0;32m    939\u001B[0m \u001B[38;5;66;03m# 1. we passed local_files_only.\u001B[39;00m\n\u001B[0;32m    940\u001B[0m \u001B[38;5;66;03m# 2. we don't have a connection\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    946\u001B[0m \u001B[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001B[39;00m\n\u001B[0;32m    947\u001B[0m \u001B[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001B[39;00m\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m head_call_error \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    949\u001B[0m     \u001B[38;5;66;03m# Couldn't make a HEAD call => let's try to find a local file\u001B[39;00m\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\file_download.py:1374\u001B[0m, in \u001B[0;36m_get_metadata_or_catch_error\u001B[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001B[0m\n\u001B[0;32m   1372\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1373\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1374\u001B[0m         metadata \u001B[38;5;241m=\u001B[39m \u001B[43mget_hf_file_metadata\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1375\u001B[0m \u001B[43m            \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43metag_timeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\n\u001B[0;32m   1376\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1377\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m EntryNotFoundError \u001B[38;5;28;01mas\u001B[39;00m http_error:\n\u001B[0;32m   1378\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m storage_folder \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m relative_filename \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1379\u001B[0m             \u001B[38;5;66;03m# Cache the non-existence of the file\u001B[39;00m\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[0;32m    112\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[1;32m--> 114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\file_download.py:1294\u001B[0m, in \u001B[0;36mget_hf_file_metadata\u001B[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001B[0m\n\u001B[0;32m   1291\u001B[0m hf_headers[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccept-Encoding\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124midentity\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001B[39;00m\n\u001B[0;32m   1293\u001B[0m \u001B[38;5;66;03m# Retrieve metadata\u001B[39;00m\n\u001B[1;32m-> 1294\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43m_request_wrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1295\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mHEAD\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1296\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1297\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhf_headers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1298\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1299\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfollow_relative_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1300\u001B[0m \u001B[43m    \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1301\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1302\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1303\u001B[0m hf_raise_for_status(r)\n\u001B[0;32m   1305\u001B[0m \u001B[38;5;66;03m# Return\u001B[39;00m\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\file_download.py:278\u001B[0m, in \u001B[0;36m_request_wrapper\u001B[1;34m(method, url, follow_relative_redirects, **params)\u001B[0m\n\u001B[0;32m    276\u001B[0m \u001B[38;5;66;03m# Recursively follow relative redirects\u001B[39;00m\n\u001B[0;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m follow_relative_redirects:\n\u001B[1;32m--> 278\u001B[0m     response \u001B[38;5;241m=\u001B[39m _request_wrapper(\n\u001B[0;32m    279\u001B[0m         method\u001B[38;5;241m=\u001B[39mmethod,\n\u001B[0;32m    280\u001B[0m         url\u001B[38;5;241m=\u001B[39murl,\n\u001B[0;32m    281\u001B[0m         follow_relative_redirects\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    282\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[0;32m    283\u001B[0m     )\n\u001B[0;32m    285\u001B[0m     \u001B[38;5;66;03m# If redirection, we redirect only relative paths.\u001B[39;00m\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;66;03m# This is useful in case of a renamed repository.\u001B[39;00m\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;241m300\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m399\u001B[39m:\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\file_download.py:301\u001B[0m, in \u001B[0;36m_request_wrapper\u001B[1;34m(method, url, follow_relative_redirects, **params)\u001B[0m\n\u001B[0;32m    298\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m response\n\u001B[0;32m    300\u001B[0m \u001B[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001B[39;00m\n\u001B[1;32m--> 301\u001B[0m response \u001B[38;5;241m=\u001B[39m get_session()\u001B[38;5;241m.\u001B[39mrequest(method\u001B[38;5;241m=\u001B[39mmethod, url\u001B[38;5;241m=\u001B[39murl, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[0;32m    302\u001B[0m hf_raise_for_status(response)\n\u001B[0;32m    303\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\requests\\sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[0;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[0;32m    587\u001B[0m }\n\u001B[0;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[1;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msend(prep, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msend_kwargs)\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\requests\\sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[0;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[1;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m adapter\u001B[38;5;241m.\u001B[39msend(request, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[0;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:93\u001B[0m, in \u001B[0;36mUniqueRequestIdAdapter.send\u001B[1;34m(self, request, *args, **kwargs)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001B[39;00m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 93\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39msend(request, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m requests\u001B[38;5;241m.\u001B[39mRequestException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     95\u001B[0m     request_id \u001B[38;5;241m=\u001B[39m request\u001B[38;5;241m.\u001B[39mheaders\u001B[38;5;241m.\u001B[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\requests\\adapters.py:667\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    664\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m TimeoutSauce(connect\u001B[38;5;241m=\u001B[39mtimeout, read\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[0;32m    666\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 667\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    668\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    669\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    670\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    671\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    672\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    673\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    674\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    675\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    676\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    677\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    678\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    679\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    681\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    682\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py:715\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[0;32m    712\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_proxy(conn)\n\u001B[0;32m    714\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n\u001B[1;32m--> 715\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    716\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    717\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    718\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    719\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    720\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    721\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    722\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    723\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    725\u001B[0m \u001B[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001B[39;00m\n\u001B[0;32m    726\u001B[0m \u001B[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001B[39;00m\n\u001B[0;32m    727\u001B[0m \u001B[38;5;66;03m# it will also try to release it and we'll have a double-release\u001B[39;00m\n\u001B[0;32m    728\u001B[0m \u001B[38;5;66;03m# mess.\u001B[39;00m\n\u001B[0;32m    729\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py:404\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[0;32m    402\u001B[0m \u001B[38;5;66;03m# Trigger any extra validation we need to do.\u001B[39;00m\n\u001B[0;32m    403\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 404\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_conn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    405\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (SocketTimeout, BaseSSLError) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    406\u001B[0m     \u001B[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001B[39;00m\n\u001B[0;32m    407\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mconn\u001B[38;5;241m.\u001B[39mtimeout)\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\urllib3\\connectionpool.py:1058\u001B[0m, in \u001B[0;36mHTTPSConnectionPool._validate_conn\u001B[1;34m(self, conn)\u001B[0m\n\u001B[0;32m   1056\u001B[0m \u001B[38;5;66;03m# Force connect early to allow us to validate the connection.\u001B[39;00m\n\u001B[0;32m   1057\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(conn, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msock\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):  \u001B[38;5;66;03m# AppEngine might not have  `.sock`\u001B[39;00m\n\u001B[1;32m-> 1058\u001B[0m     \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1060\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m conn\u001B[38;5;241m.\u001B[39mis_verified:\n\u001B[0;32m   1061\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   1062\u001B[0m         (\n\u001B[0;32m   1063\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnverified HTTPS request is being made to host \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1068\u001B[0m         InsecureRequestWarning,\n\u001B[0;32m   1069\u001B[0m     )\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\urllib3\\connection.py:363\u001B[0m, in \u001B[0;36mHTTPSConnection.connect\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    361\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconnect\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    362\u001B[0m     \u001B[38;5;66;03m# Add certificate verification\u001B[39;00m\n\u001B[1;32m--> 363\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_new_conn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    364\u001B[0m     hostname \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhost\n\u001B[0;32m    365\u001B[0m     tls_in_tls \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\urllib3\\connection.py:174\u001B[0m, in \u001B[0;36mHTTPConnection._new_conn\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    171\u001B[0m     extra_kw[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msocket_options\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msocket_options\n\u001B[0;32m    173\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 174\u001B[0m     conn \u001B[38;5;241m=\u001B[39m connection\u001B[38;5;241m.\u001B[39mcreate_connection(\n\u001B[0;32m    175\u001B[0m         (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dns_host, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mport), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mextra_kw\n\u001B[0;32m    176\u001B[0m     )\n\u001B[0;32m    178\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SocketTimeout:\n\u001B[0;32m    179\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ConnectTimeoutError(\n\u001B[0;32m    180\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    181\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnection to \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m timed out. (connect timeout=\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    182\u001B[0m         \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhost, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout),\n\u001B[0;32m    183\u001B[0m     )\n",
      "File \u001B[1;32mF:\\ProgramFile\\pytorch\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\urllib3\\util\\connection.py:85\u001B[0m, in \u001B[0;36mcreate_connection\u001B[1;34m(address, timeout, source_address, socket_options)\u001B[0m\n\u001B[0;32m     83\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m source_address:\n\u001B[0;32m     84\u001B[0m         sock\u001B[38;5;241m.\u001B[39mbind(source_address)\n\u001B[1;32m---> 85\u001B[0m     \u001B[43msock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43msa\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     86\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m sock\n\u001B[0;32m     88\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m socket\u001B[38;5;241m.\u001B[39merror \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T07:15:30.124897900Z",
     "start_time": "2025-04-28T01:39:05.576723Z"
    }
   },
   "cell_type": "code",
   "source": "rag.check_memory()",
   "id": "91d690565d0df51b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('荧光屏上没有回波是怎么回事', '荧光屏上没有回波', '荧光屏上没有回波可能由以下几个原因导致：\\n1. 在个别量程，扫描末级没有电源电压。需要检查量程的扫描末级电源电压。\\n2. 磁控管灯丝插头接触不良或磁控管灯丝电压数值不对。建议测量磁控管灯丝电压并插紧灯丝插座。\\n3. 高压整流器没有高压输出，需检查高压变压器、整流硅柱和滤波电容的质量。\\n4. 调制管衰老或者工作状态不对。需要检查调制管各级电压特别是帘栅压，并测量预调脉冲幅度。\\n5. 如果以上步骤均正常，可能涉及发射机的其他部分，请进一步排查相关部件。')]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T07:15:30.126472800Z",
     "start_time": "2025-04-28T01:39:05.750069Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "cb2219dc2db80045",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
